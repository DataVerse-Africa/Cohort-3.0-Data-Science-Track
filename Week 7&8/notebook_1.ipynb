{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54172af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (3.9.1)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.11-cp312-cp312-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.15-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.13-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.12-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.10-cp312-cp312-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy)\n",
      "  Downloading weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.11.9)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Downloading spacy-3.8.11-cp312-cp312-macosx_11_0_arm64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.13-cp312-cp312-macosx_11_0_arm64.whl (42 kB)\n",
      "Downloading murmurhash-1.0.15-cp312-cp312-macosx_11_0_arm64.whl (27 kB)\n",
      "Downloading preshed-3.0.12-cp312-cp312-macosx_11_0_arm64.whl (124 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.2-cp312-cp312-macosx_11_0_arm64.whl (653 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.2/653.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.10-cp312-cp312-macosx_11_0_arm64.whl (741 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m741.1/741.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.3-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Installing collected packages: wasabi, typer-slim, spacy-loggers, spacy-legacy, murmurhash, cymem, cloudpathlib, catalogue, blis, srsly, preshed, confection, weasel, thinc, spacy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [spacy]m14/15\u001b[0m [spacy]tion]b]\n",
      "\u001b[1A\u001b[2KSuccessfully installed blis-1.3.3 catalogue-2.0.10 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 murmurhash-1.0.15 preshed-3.0.12 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 thinc-8.3.10 typer-slim-0.20.0 wasabi-1.1.3 weasel-0.4.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn. naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# ensure nltk resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# load spacy english model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff8b37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./Corona Virus/Corona_NLP_train.csv\"\n",
    "test_path = \"./Corona Virus/Corona_NLP_test.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path, encoding='latin1')\n",
    "test = pd.read_csv(test_path, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6926a85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "UserName",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ScreenName",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Location",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "TweetAt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "OriginalTweet",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "dc2f6e70-a92b-4beb-ac48-9bfc6589fa76",
       "rows": [
        [
         "0",
         "3799",
         "48751",
         "London",
         "16-03-2020",
         "@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8",
         "Neutral"
        ],
        [
         "1",
         "3800",
         "48752",
         "UK",
         "16-03-2020",
         "advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order",
         "Positive"
        ],
        [
         "2",
         "3801",
         "48753",
         "Vagabonds",
         "16-03-2020",
         "Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P",
         "Positive"
        ],
        [
         "3",
         "3802",
         "48754",
         null,
         "16-03-2020",
         "My food stock is not the only one which is empty...\r\r\n\r\r\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \r\r\nStay calm, stay safe.\r\r\n\r\r\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j",
         "Positive"
        ],
        [
         "4",
         "3803",
         "48755",
         null,
         "16-03-2020",
         "Me, ready to go at supermarket during the #COVID19 outbreak.\r\r\n\r\r\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\r\r\n\r\r\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n",
         "Extremely Negative"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "UserName",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ScreenName",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Location",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "TweetAt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "OriginalTweet",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "77bfbd19-d6bd-4b37-b6af-36c1db3e96ed",
       "rows": [
        [
         "0",
         "1",
         "44953",
         "NYC",
         "02-03-2020",
         "TRENDING: New Yorkers encounter empty supermarket shelves (pictured, Wegmans in Brooklyn), sold-out online grocers (FoodKick, MaxDelivery) as #coronavirus-fearing shoppers stock up https://t.co/Gr76pcrLWh https://t.co/ivMKMsqdT1",
         "Extremely Negative"
        ],
        [
         "1",
         "2",
         "44954",
         "Seattle, WA",
         "02-03-2020",
         "When I couldn't find hand sanitizer at Fred Meyer, I turned to #Amazon. But $114.97 for a 2 pack of Purell??!!Check out how  #coronavirus concerns are driving up prices. https://t.co/ygbipBflMY",
         "Positive"
        ],
        [
         "2",
         "3",
         "44955",
         null,
         "02-03-2020",
         "Find out how you can protect yourself and loved ones from #coronavirus. ?",
         "Extremely Positive"
        ],
        [
         "3",
         "4",
         "44956",
         "Chicagoland",
         "02-03-2020",
         "#Panic buying hits #NewYork City as anxious shoppers stock up on food&amp;medical supplies after #healthcare worker in her 30s becomes #BigApple 1st confirmed #coronavirus patient OR a #Bloomberg staged event?\r\r\n\r\r\nhttps://t.co/IASiReGPC4\r\r\n\r\r\n#QAnon #QAnon2018 #QAnon2020 \r\r\n#Election2020 #CDC https://t.co/29isZOewxu",
         "Negative"
        ],
        [
         "4",
         "5",
         "44957",
         "Melbourne, Victoria",
         "03-03-2020",
         "#toiletpaper #dunnypaper #coronavirus #coronavirusaustralia #CoronaVirusUpdate #Covid_19 #9News  #Corvid19 #7NewsMelb #dunnypapergate #Costco    One week everyone buying baby milk powder the next everyone buying up toilet paper. https://t.co/ScZryVvsIh",
         "Neutral"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44953</td>\n",
       "      <td>NYC</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44954</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>44955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44956</td>\n",
       "      <td>Chicagoland</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44957</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>03-03-2020</td>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName             Location     TweetAt  \\\n",
       "0         1       44953                  NYC  02-03-2020   \n",
       "1         2       44954          Seattle, WA  02-03-2020   \n",
       "2         3       44955                  NaN  02-03-2020   \n",
       "3         4       44956          Chicagoland  02-03-2020   \n",
       "4         5       44957  Melbourne, Victoria  03-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
       "1  When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
       "2  Find out how you can protect yourself and love...  Extremely Positive  \n",
       "3  #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
       "4  #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b44bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1:\n",
      "@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8\n",
      "Sentiment: Neutral\n",
      "\n",
      "\n",
      "Tweet 2:\n",
      "advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order\n",
      "Sentiment: Positive\n",
      "\n",
      "\n",
      "Tweet 3:\n",
      "Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P\n",
      "Sentiment: Positive\n",
      "\n",
      "\n",
      "Tweet 4:\n",
      "My food stock is not the only one which is empty...\n",
      "\n",
      "PLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \n",
      "Stay calm, stay safe.\n",
      "\n",
      "#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j\n",
      "Sentiment: Positive\n",
      "\n",
      "\n",
      "Tweet 5:\n",
      "Me, ready to go at supermarket during the #COVID19 outbreak.\n",
      "\n",
      "Not because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\n",
      "\n",
      "#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\n",
      "Sentiment: Extremely Negative\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top 5 tweets and sentiment in training data\n",
    "top_5 = train['OriginalTweet'].tolist()[:5]\n",
    "top_5_sentiments = train['Sentiment'].tolist()[:5]\n",
    "\n",
    "for id, tweet in enumerate(top_5):\n",
    "    print(f\"Tweet {id+1}:\")\n",
    "    print(tweet)\n",
    "    print(f\"Sentiment: {top_5_sentiments[id]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a947d01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1:\n",
      "TRENDING: New Yorkers encounter empty supermarket shelves (pictured, Wegmans in Brooklyn), sold-out online grocers (FoodKick, MaxDelivery) as #coronavirus-fearing shoppers stock up https://t.co/Gr76pcrLWh https://t.co/ivMKMsqdT1\n",
      "Sentiment: Extremely Negative\n",
      "\n",
      "\n",
      "Tweet 2:\n",
      "When I couldn't find hand sanitizer at Fred Meyer, I turned to #Amazon. But $114.97 for a 2 pack of Purell??!!Check out how  #coronavirus concerns are driving up prices. https://t.co/ygbipBflMY\n",
      "Sentiment: Positive\n",
      "\n",
      "\n",
      "Tweet 3:\n",
      "Find out how you can protect yourself and loved ones from #coronavirus. ?\n",
      "Sentiment: Extremely Positive\n",
      "\n",
      "\n",
      "Tweet 4:\n",
      "#Panic buying hits #NewYork City as anxious shoppers stock up on food&amp;medical supplies after #healthcare worker in her 30s becomes #BigApple 1st confirmed #coronavirus patient OR a #Bloomberg staged event?\n",
      "\n",
      "https://t.co/IASiReGPC4\n",
      "\n",
      "#QAnon #QAnon2018 #QAnon2020 \n",
      "#Election2020 #CDC https://t.co/29isZOewxu\n",
      "Sentiment: Negative\n",
      "\n",
      "\n",
      "Tweet 5:\n",
      "#toiletpaper #dunnypaper #coronavirus #coronavirusaustralia #CoronaVirusUpdate #Covid_19 #9News  #Corvid19 #7NewsMelb #dunnypapergate #Costco    One week everyone buying baby milk powder the next everyone buying up toilet paper. https://t.co/ScZryVvsIh\n",
      "Sentiment: Neutral\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top 5 tweets and sentiment in test data\n",
    "top_5 = test['OriginalTweet'].tolist()[:5]\n",
    "top_5_sentiments = test['Sentiment'].tolist()[:5]\n",
    "\n",
    "for id, tweet in enumerate(top_5):\n",
    "    print(f\"Tweet {id+1}:\")\n",
    "    print(tweet)\n",
    "    print(f\"Sentiment: {top_5_sentiments[id]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da5c82",
   "metadata": {},
   "source": [
    "Timmy, timmy, timmY, TImmy\n",
    "\n",
    "timmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b3769a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRENDING: New Yorkers encounter empty supermarket shelves (pictured, Wegmans in Brooklyn), sold-out online grocers (FoodKick, MaxDelivery) as #coronavirus-fearing shoppers stock up https://t.co/Gr76pcrLWh https://t.co/ivMKMsqdT1'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = top_5[0]\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f7c1f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trending: new yorkers encounter empty supermarket shelves (pictured, wegmans in brooklyn), sold-out online grocers (foodkick, maxdelivery) as #coronavirus-fearing shoppers stock up https://t.co/gr76pcrlwh https://t.co/ivmkmsqdt1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting all texts to lowercase\n",
    "one = one.lower()\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e946e543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call me at  regarding the pest outbreak.\n"
     ]
    }
   ],
   "source": [
    "# removing phone numbers \n",
    "sample = \"Call me at 080-123-4567 regarding the pest outbreak.\"\n",
    "cleaned_sample = re.sub(r'\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4}', '', sample)\n",
    "print(cleaned_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c81c3cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trending: new yorkers encounter empty supermarket shelves (pictured, wegmans in brooklyn), sold-out online grocers (foodkick, maxdelivery) as #coronavirus-fearing shoppers stock up  '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing links from texts\n",
    "one = re.sub(r'http\\S+|www\\S+|https\\S+', '', one, flags=re.MULTILINE)\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b07f5d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trending new yorkers encounter empty supermarket shelves pictured wegmans in brooklyn soldout online grocers foodkick maxdelivery as coronavirusfearing shoppers stock up  \n"
     ]
    }
   ],
   "source": [
    "# removing punctuation\n",
    "one_new = one.translate(str.maketrans('', '', string.punctuation))\n",
    "print(one_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cebfd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trending',\n",
       " 'new',\n",
       " 'yorkers',\n",
       " 'encounter',\n",
       " 'empty',\n",
       " 'supermarket',\n",
       " 'shelves',\n",
       " 'pictured',\n",
       " 'wegmans',\n",
       " 'brooklyn',\n",
       " 'soldout',\n",
       " 'online',\n",
       " 'grocers',\n",
       " 'foodkick',\n",
       " 'maxdelivery',\n",
       " 'coronavirusfearing',\n",
       " 'shoppers',\n",
       " 'stock']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing stopwords\n",
    "stopwords_list = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return [word for word in text.split() if word not in stopwords_list]\n",
    "\n",
    "cleaned_one = remove_stopwords(one_new)\n",
    "cleaned_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3cb72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning function\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # Remove URLs\n",
    "    text = re.sub(r'<.*?>', '', text) # Remove HTML\n",
    "    text = re.sub(r'@\\w+', '', text) # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text) # Remove hashtags\n",
    "    # remove number\n",
    "    text = re.sub(r'\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4}', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # Remove special characters and numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf256d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the training and test data\n",
    "train['Cleaned_Tweet'] = train['OriginalTweet'].apply(clean_text)\n",
    "test['Cleaned_Tweet'] = test['OriginalTweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b62362c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OriginalTweet",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Cleaned_Tweet",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6c2b2719-e74d-46a0-b0a1-201db2ebbfbb",
       "rows": [
        [
         "0",
         "@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8",
         "and and"
        ],
        [
         "1",
         "advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order",
         "advice talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist gp set up online shopping accounts if poss adequate supplies of regular meds but not over order"
        ],
        [
         "2",
         "Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P",
         "coronavirus australia woolworths to give elderly disabled dedicated shopping hours amid covid outbreak"
        ],
        [
         "3",
         "My food stock is not the only one which is empty...\r\r\n\r\r\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \r\r\nStay calm, stay safe.\r\r\n\r\r\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j",
         "my food stock is not the only one which is empty please dont panic there will be enough food for everyone if you do not take more than you need stay calm stay safe"
        ],
        [
         "4",
         "Me, ready to go at supermarket during the #COVID19 outbreak.\r\r\n\r\r\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\r\r\n\r\r\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n",
         "me ready to go at supermarket during the outbreak not because im paranoid but because my food stock is litteraly empty the is a serious thing but please dont panic it causes shortage"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Cleaned_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>and and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>me ready to go at supermarket during the outbr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet  \\\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n",
       "1  advice Talk to your neighbours family to excha...   \n",
       "2  Coronavirus Australia: Woolworths to give elde...   \n",
       "3  My food stock is not the only one which is emp...   \n",
       "4  Me, ready to go at supermarket during the #COV...   \n",
       "\n",
       "                                       Cleaned_Tweet  \n",
       "0                                            and and  \n",
       "1  advice talk to your neighbours family to excha...  \n",
       "2  coronavirus australia woolworths to give elder...  \n",
       "3  my food stock is not the only one which is emp...  \n",
       "4  me ready to go at supermarket during the outbr...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['OriginalTweet', 'Cleaned_Tweet']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c624044c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and and',\n",
       " 'advice talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist gp set up online shopping accounts if poss adequate supplies of regular meds but not over order',\n",
       " 'coronavirus australia woolworths to give elderly disabled dedicated shopping hours amid covid outbreak',\n",
       " 'my food stock is not the only one which is empty please dont panic there will be enough food for everyone if you do not take more than you need stay calm stay safe',\n",
       " 'me ready to go at supermarket during the outbreak not because im paranoid but because my food stock is litteraly empty the is a serious thing but please dont panic it causes shortage']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_one = train['Cleaned_Tweet'].tolist()[:5]\n",
    "new_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f15dec45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advice talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist gp set up online shopping accounts if poss adequate supplies of regular meds but not over order'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=new_one[1]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f17db862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['advice',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'your',\n",
       " 'neighbours',\n",
       " 'family',\n",
       " 'to',\n",
       " 'exchange',\n",
       " 'phone',\n",
       " 'numbers',\n",
       " 'create',\n",
       " 'contact',\n",
       " 'list',\n",
       " 'with',\n",
       " 'phone',\n",
       " 'numbers',\n",
       " 'of',\n",
       " 'neighbours',\n",
       " 'schools',\n",
       " 'employer',\n",
       " 'chemist',\n",
       " 'gp',\n",
       " 'set',\n",
       " 'up',\n",
       " 'online',\n",
       " 'shopping',\n",
       " 'accounts',\n",
       " 'if',\n",
       " 'poss',\n",
       " 'adequate',\n",
       " 'supplies',\n",
       " 'of',\n",
       " 'regular',\n",
       " 'meds',\n",
       " 'but',\n",
       " 'not',\n",
       " 'over',\n",
       " 'order']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizing text\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1876f1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['advice',\n",
       " 'talk',\n",
       " 'neighbours',\n",
       " 'family',\n",
       " 'exchange',\n",
       " 'phone',\n",
       " 'numbers',\n",
       " 'create',\n",
       " 'contact',\n",
       " 'list',\n",
       " 'phone',\n",
       " 'numbers',\n",
       " 'neighbours',\n",
       " 'schools',\n",
       " 'employer',\n",
       " 'chemist',\n",
       " 'gp',\n",
       " 'set',\n",
       " 'online',\n",
       " 'shopping',\n",
       " 'accounts',\n",
       " 'poss',\n",
       " 'adequate',\n",
       " 'supplies',\n",
       " 'regular',\n",
       " 'meds',\n",
       " 'order']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stop words\n",
    "cleaned_text = [word for word in tokens if word not in stopwords_list]\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "417610aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'slept'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PorterStemmer().stem(\"slept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0588ad83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['advic',\n",
       " 'talk',\n",
       " 'neighbour',\n",
       " 'famili',\n",
       " 'exchang',\n",
       " 'phone',\n",
       " 'number',\n",
       " 'creat',\n",
       " 'contact',\n",
       " 'list',\n",
       " 'phone',\n",
       " 'number',\n",
       " 'neighbour',\n",
       " 'school',\n",
       " 'employ',\n",
       " 'chemist',\n",
       " 'gp',\n",
       " 'set',\n",
       " 'onlin',\n",
       " 'shop',\n",
       " 'account',\n",
       " 'poss',\n",
       " 'adequ',\n",
       " 'suppli',\n",
       " 'regular',\n",
       " 'med',\n",
       " 'order']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming\n",
    "ps = PorterStemmer()\n",
    "stemmed_text = [ps.stem(word) for word in cleaned_text]\n",
    "stemmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0472ab75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smoke'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordNetLemmatizer().lemmatize(\"smokes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "393ceef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['advic',\n",
       " 'talk',\n",
       " 'neighbour',\n",
       " 'famili',\n",
       " 'exchang',\n",
       " 'phone',\n",
       " 'number',\n",
       " 'creat',\n",
       " 'contact',\n",
       " 'list',\n",
       " 'phone',\n",
       " 'number',\n",
       " 'neighbour',\n",
       " 'school',\n",
       " 'employ',\n",
       " 'chemist',\n",
       " 'gp',\n",
       " 'set',\n",
       " 'onlin',\n",
       " 'shop',\n",
       " 'account',\n",
       " 'poss',\n",
       " 'adequ',\n",
       " 'suppli',\n",
       " 'regular',\n",
       " 'med',\n",
       " 'order']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_text = [lemmatizer.lemmatize(word) for word in stemmed_text]\n",
    "lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1826c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using spacy\n",
    "\n",
    "# Text with \"water\" used as a Noun and a Verb\n",
    "text = \"Timothy teaches Musonda and Thato; Data Science weekly\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e4d610b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timothy teaches Musonda and Thato; Data Science weekly"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5c4d77fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timothy PROPN nsubj proper noun\n",
      "teaches VERB ccomp verb\n",
      "Musonda PROPN dobj proper noun\n",
      "and CCONJ cc coordinating conjunction\n",
      "Thato PROPN conj proper noun\n",
      "; PUNCT punct punctuation\n",
      "Data PROPN compound proper noun\n",
      "Science PROPN nsubj proper noun\n",
      "weekly NOUN ROOT noun\n"
     ]
    }
   ],
   "source": [
    "for tok in doc:\n",
    "    print(tok.text, tok.pos_ , tok.dep_, spacy.explain(tok.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "04952e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Musonda, Thato, Data Science, weekly)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cd74984d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Musonda PERSON People, including fictional\n",
      "Thato ORG Companies, agencies, institutions, etc.\n",
      "Data Science ORG Companies, agencies, institutions, etc.\n",
      "weekly DATE Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "for tok in doc.ents:\n",
    "    print(tok.text, tok.label_, spacy.explain(tok.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031a45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. POS TAGGING (Context Matters) ---\n",
      "    Word POS Tag Explanation\n",
      "0  water    NOUN        noun\n",
      "1  water    VERB        verb\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for token in doc:\n",
    "    if token.text.lower() == \"water\":\n",
    "        description = spacy.explain(token.pos_)\n",
    "        data.append([token.text, token.pos_, description])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Word\", \"POS Tag\", \"Explanation\"])\n",
    "print(\"--- 1. POS TAGGING (Context Matters) ---\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "394ac2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- A. POS TAGGING (Grammar & Syntax) ---\n",
      "         Word POS Tag      Meaning\n",
      "0     Dangote   PROPN  proper noun\n",
      "1  Fertilizer   PROPN  proper noun\n",
      "2          is     AUX    auxiliary\n",
      "3     selling    VERB         verb\n",
      "4        Urea   PROPN  proper noun\n",
      "5         for     ADP   adposition\n",
      "6     N15,000   PROPN  proper noun\n",
      "7          in     ADP   adposition\n",
      "8       Lagos   PROPN  proper noun\n",
      "9           .   PUNCT  punctuation\n"
     ]
    }
   ],
   "source": [
    "# Input Text: Contains Companies, Locations, Money, and Verbs\n",
    "text = \"Dangote Fertilizer is selling Urea for N15,000 in Lagos.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# --- PART A: POS TAGGING (Grammar) ---\n",
    "# Goal: Find the Verbs and Nouns\n",
    "pos_data = []\n",
    "for token in doc:\n",
    "    # We get the simple tag (pos_) and the detailed tag (tag_)\n",
    "    pos_data.append([\n",
    "        token.text,\n",
    "        token.pos_,\n",
    "        spacy.explain(token.pos_)\n",
    "    ])\n",
    "\n",
    "print(\"\\n--- A. POS TAGGING (Grammar & Syntax) ---\")\n",
    "df_pos = pd.DataFrame(pos_data, columns=[\"Word\", \"POS Tag\", \"Meaning\"])\n",
    "print(df_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33ee1170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- B. NAMED ENTITY RECOGNITION (Real World Objects) ---\n",
      "  Entity Text   Label                  Description\n",
      "0  Fertilizer  PERSON  People, including fictional\n",
      "1        Urea     GPE    Countries, cities, states\n",
      "2     N15,000     GPE    Countries, cities, states\n",
      "3       Lagos     GPE    Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "# --- PART B: NER (Named Entities) ---\n",
    "# Goal: Find the Real-World Objects (Who, Where, How Much)\n",
    "ner_data = []\n",
    "for ent in doc.ents:\n",
    "    ner_data.append([\n",
    "        ent.text,\n",
    "        ent.label_,\n",
    "        spacy.explain(ent.label_)\n",
    "    ])\n",
    "\n",
    "print(\"\\n--- B. NAMED ENTITY RECOGNITION (Real World Objects) ---\")\n",
    "df_ner = pd.DataFrame(ner_data, columns=[\"Entity Text\", \"Label\", \"Description\"])\n",
    "print(df_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c0e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
